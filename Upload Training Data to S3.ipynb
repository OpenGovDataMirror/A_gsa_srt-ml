{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload Training Data to s3\n",
    "This notebook assumes:\n",
    " - You've got all of the labeled solicitaton documents within a directory named `labeled_fbo_docs`.\n",
    " - You can use the `awscli` and have configured it. See [this](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html) for instructions. We recommend placing the credentials in a shared credential file (`~/.aws/credentials`)\n",
    " - You have already created an S3 bucket (ours is named `srt-sm`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the training data\n",
    "\n",
    "Below, we'll read in the labeled documents and extract the text along with the label (the label is in the file name). \n",
    "\n",
    ">Although there are three lables (red, yellow and green), we're combining red and yellow as noncompliant ($0$) and treating green as compliant ($1$). This makes a binary classification challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done reading in 993 documents.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "data = []\n",
    "for file in os.listdir('labeled_fbo_docs'):\n",
    "    if file.startswith('GREEN'):\n",
    "        target = 1\n",
    "    elif file.startswith('RED') or file.startswith('YELLOW'):\n",
    "        target = 0\n",
    "    else:\n",
    "        raise Exception(f\"A file isn't prepended with the target:  {file}\")\n",
    "\n",
    "    file_path = os.path.join(os.getcwd(), 'labeled_fbo_docs', file)\n",
    "    with open(file_path, 'r', errors = 'ignore') as f:\n",
    "        #do some newline replacing\n",
    "        text = f.read().replace(\"\\n\", ' ').strip()\n",
    "    data.append([target, text])\n",
    "    \n",
    "print(f\"Done reading in {len(data)} documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the samples into training and test datasets\n",
    "Since our data is imbalanced, we'll use the `stratify` method to split the data in a balanced fashion, using the labels array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.33% of the training data is a positive sample\n",
      "27.14% of the testing data is a positive sample\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = [i[0] for i in data]\n",
    "x = [i[1] for i in data]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=123, stratify=y)\n",
    "\n",
    "n_test_pos_samples = 100 * sum(y_test) / len(y_test)\n",
    "n_train_pos_samples = 100 * sum(y_train) / len(y_train)\n",
    "\n",
    "print(\"{:.2f}% of the training data is a positive sample\".format(n_train_pos_samples))\n",
    "\n",
    "print(\"{:.2f}% of the testing data is a positive sample\".format(n_test_pos_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write the training data to csv\n",
    "Here we'll write the training and test data to two csvs, using pandas to keep it simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.DataFrame([y_train, X_train]).transpose()\n",
    "\n",
    "test_df = pd.DataFrame([y_test, X_test]).transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('srt_train.csv', index = False)\n",
    "\n",
    "test_df.to_csv('srt_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll read in the files we wrote just to make sure we do it correctly in our sagemaker notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>OBJECTIVE    The RRB seeks electronic data sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Checklist and Certification for Minimum Level ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Date Issued:  January 6, 2009 Date Due:  Febru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Section SF 1449 - CONTINUATION SHEET    |ITEM ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Statement of Work                             ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0     0.0  OBJECTIVE    The RRB seeks electronic data sto...\n",
       "1     0.0  Checklist and Certification for Minimum Level ...\n",
       "2     1.0  Date Issued:  January 6, 2009 Date Due:  Febru...\n",
       "3     0.0  Section SF 1449 - CONTINUATION SHEET    |ITEM ...\n",
       "4     1.0  Statement of Work                             ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "test_df_check = pd.read_csv('srt_test.csv')\n",
    "test_df_check.columns = ['target', 'text']\n",
    "test_df_check = test_df_check.astype({'target': np.float64, 'text': str})\n",
    "\n",
    "test_df_check.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Push training data to S3\n",
    "Here we push the data to our s3 bucket, using a prefix that describes our project and the model we're going to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done writing to s3n://srt-sm/Sklearn-RandomizedGridSearch/srt_train.csv\n",
      "Done writing to s3n://srt-sm/Sklearn-RandomizedGridSearch/srt_test.csv\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "region = boto3.Session().region_name\n",
    "bucket = 'srt-sm' \n",
    "prefix = 'Sklearn-RandomizedGridSearch'\n",
    "bucket_path = f'https://s3-{region}.amazonaws.com/{bucket}'\n",
    "\n",
    "for f in ['srt_train.csv', 'srt_test.csv']:\n",
    "    key = f'{prefix}/{f}'\n",
    "    s3.Bucket(bucket).Object(key).upload_file(f)\n",
    "    url = f's3n://{bucket}/{key}'\n",
    "    print(f'Done writing to {url}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tokenization",
   "language": "python",
   "name": "tokenization"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
